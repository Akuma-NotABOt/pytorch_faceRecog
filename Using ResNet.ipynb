{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c808fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2499df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your training and test data directories\n",
    "# The images should be in seperate folders labelled with their corresponding names\n",
    "train_data_dir = r\"C:\\Users\\jv258\\Documents\\Jupyter\\Projects\\Jodhpur\\Images\\Train\" #Edit path to Training image\n",
    "test_data_dir = r\"C:\\Users\\jv258\\Documents\\Jupyter\\Projects\\Jodhpur\\Images\\Test\" #Edit path to Test images\n",
    "\n",
    "# Define the image dimensions and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2909a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocess\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f607418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#test data preprocess\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f73b4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model \n",
    "base_model = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_width, img_height, 3)\n",
    ")\n",
    "\n",
    "# Add a global average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "output = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad51ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "451853bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2/2 [==============================] - 24s 5s/step - loss: 2.5186 - accuracy: 0.2326 - val_loss: 3.6434 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 14s 8s/step - loss: 2.2466 - accuracy: 0.3438 - val_loss: 3.7070 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 15s 8s/step - loss: 1.1278 - accuracy: 0.6250 - val_loss: 3.1526 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 16s 10s/step - loss: 0.7566 - accuracy: 0.7188 - val_loss: 2.9868 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 16s 12s/step - loss: 0.4056 - accuracy: 0.8605 - val_loss: 2.5275 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 16s 7s/step - loss: 0.4137 - accuracy: 0.8605 - val_loss: 3.0620 - val_accuracy: 0.2188 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 16s 7s/step - loss: 0.4294 - accuracy: 0.9070 - val_loss: 3.6406 - val_accuracy: 0.1875 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.8281\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "2/2 [==============================] - 21s 12s/step - loss: 0.6914 - accuracy: 0.8281 - val_loss: 3.0526 - val_accuracy: 0.1719 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 21s 12s/step - loss: 0.2586 - accuracy: 0.9219 - val_loss: 2.6797 - val_accuracy: 0.1719 - lr: 2.0000e-04\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 21s 12s/step - loss: 0.2518 - accuracy: 0.9062 - val_loss: 2.3366 - val_accuracy: 0.2344 - lr: 2.0000e-04\n",
      "Epoch 11/15\n",
      "2/2 [==============================] - 15s 12s/step - loss: 0.2650 - accuracy: 0.8837 - val_loss: 2.4469 - val_accuracy: 0.2031 - lr: 2.0000e-04\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 13s 5s/step - loss: 0.4670 - accuracy: 0.8605 - val_loss: 2.7595 - val_accuracy: 0.1875 - lr: 2.0000e-04\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1673 - accuracy: 0.9070\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.1673 - accuracy: 0.9070 - val_loss: 2.7906 - val_accuracy: 0.1875 - lr: 2.0000e-04\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 10s 8s/step - loss: 0.1420 - accuracy: 0.9302 - val_loss: 2.6898 - val_accuracy: 0.2031 - lr: 4.0000e-05\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 10s 8s/step - loss: 0.0931 - accuracy: 0.9767 - val_loss: 2.5378 - val_accuracy: 0.2188 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=15,  # Increase the number of epochs if needed\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save('ResNet50_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44a8c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 712ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Predicted Person: Keira Knightley\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Predicted Person: Barack Obama\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Predicted Person: Barack Obama\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('ResNet50_model.h5')\n",
    "\n",
    "\n",
    "# Set the path to the folder containing the images\n",
    "folder_path = r\"C:\\Users\\jv258\\Documents\\Jupyter\\Projects\\Jodhpur\\Images\\Test\\Tom Cruise\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    image_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Read and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)         \n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    \n",
    "    # Make predictions\n",
    "    pred = loaded_model.predict(image)\n",
    "    pred_label = np.argmax(pred)\n",
    "    \n",
    "    # Map label index to person name\n",
    "    class_labels = train_generator.class_indices\n",
    "    person_label = {v: k for k, v in class_labels.items()}\n",
    "    pred_person = person_label[pred_label]\n",
    "        \n",
    "    print('Predicted Person:', pred_person)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc476e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
